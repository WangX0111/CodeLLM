{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取代码文件\n",
    "# path = '/root/wang/LLVM/mlir/test/Transforms/promote-buffers-to-stack.mlir'\n",
    "# path = '/root/wang/LLVM/mlir/test/Dialect/SparseTensor/convert_sparse2dense.mlir'\n",
    "path = '/root/wang/LLVM/mlir/test/Dialect/Linalg/canonicalize.mlir'\n",
    "with open(path, \"r\") as file:\n",
    "    code_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// RUN: mlir-opt %s -canonicalize=\"test-convergence\" -split-input-file | FileCheck %s\n",
      "\n",
      "// CHECK-LABEL: func @memref_cast(\n",
      "func.func @memref_cast(%a: index, %b: index) -> memref<?x?xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c8 = arith.constant 8 : index\n",
      "  %c16 = arith.constant 16 : index\n",
      "  %1 = memref.alloc (%b) : memref<?xi8>\n",
      "  %2 = memref.view %1[%c0][] : memref<?xi8> to memref<16x16xf32>\n",
      "  %3 = memref.cast %2 : memref<16x16xf32> to memref<?x?xf32>\n",
      "\n",
      "  // CHECK:  linalg.matmul ins({{.*}}memref<16x16xf32>, memref<16x16xf32>) outs({{.*}}memref<16x16xf32>)\n",
      "  linalg.matmul ins(%3, %3: memref<?x?xf32>, memref<?x?xf32>)\n",
      "               outs(%3: memref<?x?xf32>)\n",
      "  return %3: memref<?x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#accesses = [\n",
      "  affine_map<(i) -> (i)>\n",
      "]\n",
      "\n",
      "#trait = {\n",
      "  indexing_maps = #accesses,\n",
      "  iterator_types = [\"parallel\"]\n",
      "}\n",
      "\n",
      "func.func @dce_zero_memref(%arg0 : memref<0xf32>, %arg1: tensor<0xf32>) -> tensor<0xf32> {\n",
      "  // memref<0x32> is expected to be dce'ed\n",
      "  memref.copy %arg0, %arg0 : memref<0xf32> to memref<0xf32>\n",
      "\n",
      "  // tensor<0xf32> cannot be dce'ed\n",
      "  %1 = linalg.generic #trait outs(%arg1 : tensor<0xf32>) {\n",
      "  ^bb(%0: f32) :\n",
      "    linalg.yield %0 : f32\n",
      "  } -> tensor<0xf32>\n",
      "\n",
      "  return %1: tensor<0xf32>\n",
      "}\n",
      "// CHECK-LABEL: @dce_zero_memref\n",
      "//  CHECK-SAME:   %[[ARG0:[a-zA-Z0-9_]+]]: memref<0xf32>\n",
      "//  CHECK-SAME:   %[[ARG1:[a-zA-Z0-9_]+]]: tensor<0xf32>\n",
      "//   CHECK-NOT:   memref.copy\n",
      "//  CHECK-NEXT:   return %[[ARG1]]\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @tensor.cast(\n",
      "func.func @tensor.cast(%a : tensor<3x4xf32>, %b : tensor<4x?xf32>, %c : tensor<3x?xf32>)\n",
      "  -> tensor<3x?xf32>\n",
      "{\n",
      "  %ta = tensor.cast %a : tensor<3x4xf32> to tensor<?x?xf32>\n",
      "  %tb = tensor.cast %b : tensor<4x?xf32> to tensor<?x?xf32>\n",
      "  %tc = tensor.cast %c : tensor<3x?xf32> to tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  linalg.matmul ins({{.*}}tensor<3x4xf32>, tensor<4x?xf32>)\n",
      "  // CHECK-SAME:    outs({{.*}}tensor<3x?xf32>) -> tensor<3x?xf32>\n",
      "  %0 = linalg.matmul ins(%ta, %tb: tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "                    outs(%tc: tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<3x?xf32>\n",
      "\n",
      "  return %1: tensor<3x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @tensor.cast.unranked(\n",
      "func.func @tensor.cast.unranked(%a : tensor<*xf32>, %b : tensor<*xf32>, %c : tensor<*xf32>)\n",
      "  -> tensor<*xf32>\n",
      "{\n",
      "  //      CHECK:  tensor.cast\n",
      "  //      CHECK:  tensor.cast\n",
      "  //      CHECK:  tensor.cast\n",
      "  %ta = tensor.cast %a : tensor<*xf32> to tensor<?x?xf32>\n",
      "  %tb = tensor.cast %b : tensor<*xf32> to tensor<?x?xf32>\n",
      "  %tc = tensor.cast %c : tensor<*xf32> to tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  linalg.matmul ins({{.*}}tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "  // CHECK-SAME:    outs({{.*}}tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "  %0 = linalg.matmul ins(%ta, %tb: tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "                    outs(%tc: tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  tensor.cast\n",
      "  %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<*xf32>\n",
      "\n",
      "  return %1: tensor<*xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @linalg_effects(\n",
      "//  CHECK-SAME:     %[[A:[a-z0-9]*]]: tensor<?x?xf32>\n",
      "//  CHECK-SAME:     %[[B:[a-z0-9]*]]: memref<?x?xf32>\n",
      "//  CHECK-SAME:     %[[C:[a-z0-9]*]]: tensor<?x?xf32>\n",
      "func.func @linalg_effects(%a : tensor<?x?xf32>, %b : memref<?x?xf32>, %c : tensor<?x?xf32>) {\n",
      "  // CHECK-NOT:   %{{.*}} = linalg.matmul\n",
      "  %t = linalg.matmul ins(%a, %b : tensor<?x?xf32>, memref<?x?xf32>)\n",
      "                    outs(%c : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  // CHECK:   linalg.matmul\n",
      "  linalg.matmul ins(%a, %c : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "               outs(%b : memref<?x?xf32>)\n",
      "  return\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "func.func @remove_no_op(%arg0 : tensor<?x?x?xf32>, %arg1 : tensor<?x?x?xf32>)\n",
      "  -> (tensor<?x?x?xf32>, tensor<?x?x?xf32>) {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<?x?x?xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32>\n",
      "  %2 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32>\n",
      "  %3 = tensor.empty(%0, %1, %2) : tensor<?x?x?xf32>\n",
      "  %4, %5 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0, %arg1 : tensor<?x?x?xf32>, tensor<?x?x?xf32>)\n",
      "    outs(%3, %3 : tensor<?x?x?xf32>, tensor<?x?x?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32, %arg4 : f32, %arg5 : f32):\n",
      "    linalg.yield %arg3, %arg2 : f32, f32\n",
      "  } -> (tensor<?x?x?xf32>, tensor<?x?x?xf32>)\n",
      "  return %4, %5 : tensor<?x?x?xf32>, tensor<?x?x?xf32>\n",
      "}\n",
      "// CHECK-LABEL: func @remove_no_op\n",
      "//  CHECK-SAME:   %[[ARG0:[a-zA-Z0-9_]+]]: tensor<?x?x?xf32>\n",
      "//  CHECK-SAME:   %[[ARG1:[a-zA-Z0-9_]+]]: tensor<?x?x?xf32>\n",
      "//       CHECK:     return %[[ARG1]], %[[ARG0]]\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "func.func @remove_no_op_mismatched_types(%arg0 : tensor<?x?x?xf32>)\n",
      "  -> tensor<1x2x3xf32> {\n",
      "  %out = tensor.empty() : tensor<1x2x3xf32>\n",
      "  %g = linalg.generic {\n",
      "    indexing_maps = [#map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0 : tensor<?x?x?xf32>)\n",
      "    outs(%out : tensor<1x2x3xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32):\n",
      "    linalg.yield %arg2 : f32\n",
      "  } -> (tensor<1x2x3xf32>)\n",
      "  return %g : tensor<1x2x3xf32>\n",
      "}\n",
      "// CHECK-LABEL: func @remove_no_op_mismatched_types\n",
      "//  CHECK-SAME:   %[[ARG0:[a-zA-Z0-9_]+]]: tensor<?x?x?xf32>\n",
      "//       CHECK:     %[[CAST:.*]] = tensor.cast %[[ARG0]] : tensor<?x?x?xf32> to tensor<1x2x3xf32>\n",
      "//       CHECK:     return %[[CAST]]\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<() -> ()>\n",
      "func.func @cant_fold_to_tensor_cast(%arg0 : f32) -> tensor<f32> {\n",
      "  %out = tensor.empty() : tensor<f32>\n",
      "  %g = linalg.generic {\n",
      "    indexing_maps = [#map, #map],\n",
      "    iterator_types = []\n",
      "  } ins(%arg0 : f32)\n",
      "    outs(%out : tensor<f32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32):\n",
      "    linalg.yield %arg2 : f32\n",
      "  } -> (tensor<f32>)\n",
      "  return %g : tensor<f32>\n",
      "}\n",
      "// CHECK-LABEL: func @cant_fold_to_tensor_cast\n",
      "//       CHECK:     linalg.generic\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1) -> (d0, d1)>\n",
      "func.func @keep_not_noop(%arg0 : tensor<?x?xf32>) -> tensor<?x?xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %cst = arith.constant 1.000000e+00 : f32\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<?x?xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<?x?xf32>\n",
      "  %2 = tensor.empty(%0, %1) : tensor<?x?xf32>\n",
      "  cf.br ^bb1(%cst : f32)\n",
      "\n",
      "^bb1(%arg1 : f32):\n",
      "  %3 = linalg.generic\n",
      "    {indexing_maps = [#map, #map], iterator_types = [\"parallel\", \"parallel\"]}\n",
      "    ins(%arg0 : tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) {\n",
      "    ^bb0(%arg2: f32, %arg3 : f32):\n",
      "      linalg.yield %arg1 : f32\n",
      "    } -> tensor<?x?xf32>\n",
      "  return %3 : tensor<?x?xf32>\n",
      "}\n",
      "// CHECK-LABEL: func @keep_not_noop\n",
      "//       CHECK:   %[[RESULT:.+]] = linalg.generic\n",
      "//       CHECK:   return %[[RESULT]]\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1) -> (d0, d1)>\n",
      "func.func @keep_not_noop(%arg0 : tensor<?x?xf32>, %arg1 : tensor<?x?xf32>)\n",
      "  -> (tensor<?x?xf32>, tensor<?x?xf32>) {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %cst = arith.constant 1.000000e+00 : f32\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<?x?xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<?x?xf32>\n",
      "  %2 = tensor.empty(%0, %1) : tensor<?x?xf32>\n",
      "  cf.br ^bb1(%cst : f32)\n",
      "\n",
      "^bb1(%arg2 : f32):\n",
      "  %3:2 = linalg.generic\n",
      "    {indexing_maps = [#map, #map, #map, #map],\n",
      "     iterator_types = [\"parallel\", \"parallel\"]}\n",
      "    ins(%arg0, %arg1 : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "    outs(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) {\n",
      "    ^bb0(%arg3: f32, %arg4 : f32, %arg5 : f32, %arg6 : f32):\n",
      "      linalg.yield %arg2, %arg4 : f32, f32\n",
      "    } -> (tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "  return %3#0, %3#1 : tensor<?x?xf32>, tensor<?x?xf32>\n",
      "}\n",
      "// CHECK-LABEL: func @keep_not_noop\n",
      "//       CHECK:   %[[RESULT:.+]]:2 = linalg.generic\n",
      "//       CHECK:   return %[[RESULT]]#0, %[[RESULT]]#1\n",
      "\n",
      "// -----\n",
      "\n",
      "#accesses = [\n",
      "  affine_map<(i, j) -> (i, j)>\n",
      "]\n",
      "\n",
      "#trait = {\n",
      "  indexing_maps = #accesses,\n",
      "  iterator_types = [\"parallel\", \"parallel\"]\n",
      "}\n",
      "\n",
      "// CHECK-LABEL: func @dead_linalg_tensor\n",
      "//   CHECK-NOT:   linalg.fill\n",
      "//   CHECK-NOT:   linalg.matmul\n",
      "//   CHECK-NOT:   linalg.generic\n",
      "//   CHECK-NOT:   tensor.pad\n",
      "//       CHECK:   return\n",
      "func.func @dead_linalg_tensor(%arg0 : tensor<7x7xi32>, %arg1 : tensor<7x7xf32>,\n",
      "                         %arg2: tensor<?x?xf32>, %high : index) {\n",
      "  %c0_i32 = arith.constant 0 : i32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %cst = arith.constant 0.000000e+00 : f32\n",
      "  %0 = linalg.fill ins(%c0_i32 : i32) outs(%arg0 : tensor<7x7xi32>) -> tensor<7x7xi32>\n",
      "  %1 = linalg.matmul ins(%arg1, %arg1: tensor<7x7xf32>, tensor<7x7xf32>)\n",
      "                     outs(%arg1: tensor<7x7xf32>) -> tensor<7x7xf32>\n",
      "  %2 = linalg.generic #trait outs(%arg0 : tensor<7x7xi32>) {\n",
      "  ^bb(%3: i32) :\n",
      "    linalg.yield %3 : i32\n",
      "  } -> tensor<7x7xi32>\n",
      "  %3 = tensor.pad %arg2 low[%c0, %c0] high[%high, %high] {\n",
      "        ^bb0(%arg9: index, %arg10: index):\n",
      "          tensor.yield %cst : f32\n",
      "  } : tensor<?x?xf32> to tensor<2x4xf32>\n",
      "  return\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "func.func @propogate_casts(%arg0 : tensor<?x?xf32>, %arg1 : f32, %arg2 : index,\n",
      "    %arg3 : index) -> tensor<?x?xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c21 = arith.constant 21 : index\n",
      "  %c42 = arith.constant 42 : index\n",
      "  %0 = tensor.empty(%c21, %c42) : tensor<?x?xf32>\n",
      "  %1 = linalg.fill ins(%arg1 : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "  %2 = tensor.dim %arg0, %c0 : tensor<?x?xf32>\n",
      "  %3 = tensor.dim %arg0, %c1 : tensor<?x?xf32>\n",
      "  %4 = tensor.insert_slice %arg0 into %1[%arg2, %arg3] [%2, %3] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>\n",
      "  return %4 : tensor<?x?xf32>\n",
      "}\n",
      "// CHECK-LABEL: func @propogate_casts\n",
      "//       CHECK:   %[[INIT:.+]] = tensor.empty\n",
      "//       CHECK:   %[[FILL:.+]] = linalg.fill ins(%{{.+}}{{.*}}outs(%[[INIT]]\n",
      "//       CHECK:   %[[INSERTED:.+]] = tensor.insert_slice %{{.+}} into %[[FILL]]\n",
      "//       CHECK:   %[[RESULT:.+]] = tensor.cast %[[INSERTED]]\n",
      "//       CHECK:   return %[[RESULT]]\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: @self_copy\n",
      "func.func @self_copy(%arg0 : memref<2x3x?x4xf32>) {\n",
      "\n",
      "//   CHECK-NOT: memref.copy\n",
      "  memref.copy %arg0, %arg0 : memref<2x3x?x4xf32> to memref<2x3x?x4xf32>\n",
      "\n",
      "//   CHECK: return\n",
      "  return\n",
      "}\n",
      "\n",
      "// -----\n",
      "// CHECK-LABEL: func @fold_fill_reshape()\n",
      "func.func @fold_fill_reshape() -> tensor<6x4xf32> {\n",
      "  %zero = arith.constant 0.0 : f32\n",
      "  %empty = tensor.empty() : tensor<1x2x3x4xf32>\n",
      "  // CHECK:      %[[COLLAPSE:.+]] = tensor.collapse_shape\n",
      "  // CHECK-NEXT: %[[FILL:.+]] = linalg.fill ins(%cst : f32)\n",
      "  // CHECK-SAME:   outs(%[[COLLAPSE]] : tensor<6x4xf32>)\n",
      "  %fill = linalg.fill ins(%zero : f32) outs(%empty : tensor<1x2x3x4xf32>) -> tensor<1x2x3x4xf32>\n",
      "  %reshape = tensor.collapse_shape %fill [[0, 1, 2], [3]]\n",
      "      : tensor<1x2x3x4xf32> into tensor<6x4xf32>\n",
      "  // CHECK: return %[[FILL]] : tensor<6x4xf32>\n",
      "  return %reshape : tensor<6x4xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "//       CHECK: func @fold_fill_reshape_dynamic\n",
      "//  CHECK-SAME:   %[[ARG0:.+]]: tensor<?x?x?x?x?xf32>\n",
      "func.func @fold_fill_reshape_dynamic(%arg0 : tensor<?x?x?x?x?xf32>) -> tensor<?x?xf32> {\n",
      "  %zero = arith.constant 0.0 : f32\n",
      "  // CHECK: %[[RESHAPE:.+]] = tensor.collapse_shape %[[ARG0]]\n",
      "  %0 = linalg.fill ins(%zero : f32) outs(%arg0 : tensor<?x?x?x?x?xf32>) -> tensor<?x?x?x?x?xf32>\n",
      "  // CHECK: %[[RESULT:.+]] = linalg.fill ins(%{{.+}}{{.*}}outs(%[[RESHAPE]]\n",
      "  %1 = tensor.collapse_shape %0 [[0, 1, 2], [3, 4]]\n",
      "      : tensor<?x?x?x?x?xf32> into tensor<?x?xf32>\n",
      "  // CHECK: return %[[RESULT]]\n",
      "  return %1 : tensor<?x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK: func @fold_self_copy\n",
      "func.func @fold_self_copy(%0 : memref<4x16xf32>) {\n",
      "// CHECK-NEXT: return\n",
      "  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>,\n",
      "                                   affine_map<(d0, d1) -> (d0, d1)>],\n",
      "                  iterator_types = [\"parallel\", \"parallel\"]}\n",
      "    ins(%0 : memref<4x16xf32>)\n",
      "    outs(%0 : memref<4x16xf32>) {\n",
      "      ^bb0(%arg4: f32, %arg5: f32):\n",
      "        linalg.yield %arg4 : f32\n",
      "    }\n",
      "  return\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @fold_static_pad_fill\n",
      "//       CHECK:   %[[F0:.+]] = arith.constant 0.000000e+00 : f32\n",
      "//       CHECK:   %[[INIT:.+]] = tensor.empty() : tensor<412x276xf32>\n",
      "//       CHECK:   %[[FILL:.+]] = linalg.fill ins(%[[F0]]{{.*}}outs(%[[INIT]]\n",
      "//       CHECK:   return %[[FILL]]\n",
      "func.func @fold_static_pad_fill() -> tensor<412x276xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %empty = tensor.empty() : tensor<400x273xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<400x273xf32>) -> tensor<400x273xf32>\n",
      "  %pad = tensor.pad %fill low[4, 1] high[8, 2] {\n",
      "  ^bb0(%arg1: index, %arg2: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<400x273xf32> to tensor<412x276xf32>\n",
      "  return %pad : tensor<412x276xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK: #[[MAP0:.+]] = affine_map<()[s0] -> (s0 + 9)>\n",
      "// CHECK: #[[MAP1:.+]] = affine_map<()[s0] -> (s0 + 10)>\n",
      "// CHECK: #[[MAP2:.+]] = affine_map<()[s0] -> (s0 + 23)>\n",
      "// CHECK: #[[MAP3:.+]] = affine_map<()[s0, s1] -> (s0 + s1 + 32)>\n",
      "\n",
      "//      CHECK: func @fold_dynamic_pad_fill\n",
      "// CHECK-SAME: %[[SRC:.+]]: tensor<8x?x16x32xf32>, %[[LOW0:.+]]: index, %[[LOW3:.+]]: index, %[[HIGH2:.+]]: index, %[[HIGH3:.+]]: index\n",
      "\n",
      "//  CHECK-DAG:   %[[I1:.+]] = arith.constant 1 : index\n",
      "//  CHECK-DAG:   %[[F0:.+]] = arith.constant 0.000000e+00 : f32\n",
      "//      CHECK:   %[[OF:.+]] = linalg.fill ins(%[[F0]] : f32) outs(%[[SRC]] : tensor<8x?x16x32xf32>)\n",
      "//      CHECK:   %[[S0:.+]] = affine.apply #[[MAP0]]()[%[[LOW0]]]\n",
      "//      CHECK:   %[[DIM1:.+]] = tensor.dim %[[OF]], %[[I1]] : tensor<8x?x16x32xf32>\n",
      "//      CHECK:   %[[S1:.+]] = affine.apply #[[MAP1]]()[%[[DIM1]]]\n",
      "//      CHECK:   %[[S2:.+]] = affine.apply #[[MAP2]]()[%[[HIGH2]]]\n",
      "//      CHECK:   %[[S3:.+]] = affine.apply #[[MAP3]]()[%[[LOW3]], %[[HIGH3]]]\n",
      "//      CHECK:   %[[INIT:.+]] = tensor.empty(%[[S0]], %[[S1]], %[[S2]], %[[S3]]) : tensor<?x?x?x?xf32>\n",
      "//      CHECK:   %[[FILL:.+]] = linalg.fill ins(%[[F0]]{{.*}}outs(%[[INIT]]\n",
      "//      CHECK:   return %[[FILL]]\n",
      "func.func @fold_dynamic_pad_fill(%empty: tensor<8x?x16x32xf32>, %low0: index, %low3: index, %high2: index, %high3: index) -> tensor<?x?x?x?xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x?x16x32xf32>) -> tensor<8x?x16x32xf32>\n",
      "  %pad = tensor.pad %fill low[%low0, 8, 7, %low3] high[1, 2, %high2, %high3] {\n",
      "  ^bb0(%arg1: index, %arg2: index, %arg3: index, %arg4: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<8x?x16x32xf32> to tensor<?x?x?x?xf32>\n",
      "  return %pad : tensor<?x?x?x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @no_fold_pad_fill_value_mismatch\n",
      "func.func @no_fold_pad_fill_value_mismatch() -> tensor<412x276xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %f1 = arith.constant 1.0 : f32\n",
      "  %empty = tensor.empty() : tensor<400x273xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<400x273xf32>) -> tensor<400x273xf32>\n",
      "  // CHECK: tensor.pad\n",
      "  %pad = tensor.pad %fill low[4, 1] high[8, 2] {\n",
      "  ^bb0(%arg1: index, %arg2: index):\n",
      "    tensor.yield %f1 : f32\n",
      "  } : tensor<400x273xf32> to tensor<412x276xf32>\n",
      "  return %pad : tensor<412x276xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// Tests below verify whether static information is propagated through all the operands of generic op.\n",
      "// 1. If one of the inputs of generic op has static info and it has no cast source.\n",
      "// 2. If one of the inputs of generic op has static info and it is coming from tensr.cast operation.\n",
      "// 3. If one of the outputs of generic op has static info and it is coming from tenso.cast operation.\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "// CHECK-LABEL: func @static_input_without_cast\n",
      "// CHECK-SAME:  (%[[ARG0:.*]]: tensor<2x3x4xf32>, %[[ARG1:.*]]: tensor<?x?x?xf32>) -> tensor<2x3x4xf32> {\n",
      "func.func @static_input_without_cast(%arg0 : tensor<2x3x4xf32>, %arg1: tensor<?x?x?xf32>) -> tensor<2x3x4xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<2x3x4xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<2x3x4xf32>\n",
      "  %2 = tensor.dim %arg0, %c2 : tensor<2x3x4xf32>\n",
      "  %3 = tensor.empty(%0, %1, %2) : tensor<?x?x?xf32>\n",
      "  %4 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0, %arg1 : tensor<2x3x4xf32>, tensor<?x?x?xf32>)\n",
      "    outs(%3 : tensor<?x?x?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32, %arg4 : f32):\n",
      "    %9 = arith.addf %arg2, %arg3 : f32\n",
      "    linalg.yield %9 : f32\n",
      "  } -> (tensor<?x?x?xf32>)\n",
      "  %5 = tensor.cast %4 : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "  return %5 : tensor<2x3x4xf32>\n",
      "    //  CHECK:      %[[CAST_ARG1:.*]] = tensor.cast %[[ARG1]] : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "    //  CHECK-NEXT: %[[GENERIC_OP:.*]] = linalg.generic\n",
      "    //  CHECK-SAME: ins(%[[ARG0]], %[[CAST_ARG1]] : tensor<2x3x4xf32>, tensor<2x3x4xf32>)\n",
      "    //  CHECK-SAME: outs({{.*}} : tensor<2x3x4xf32>)\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "// CHECK-LABEL: func @static_input_with_cast\n",
      "// CHECK-SAME:  (%[[ARG0:.*]]: tensor<2x3x4xf32>, %[[ARG1:.*]]: tensor<?x?x?xf32>) -> tensor<2x3x4xf32> {\n",
      "func.func @static_input_with_cast(%arg0 : tensor<2x3x4xf32>, %arg1: tensor<?x?x?xf32>) -> tensor<2x3x4xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<2x3x4xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<2x3x4xf32>\n",
      "  %2 = tensor.dim %arg0, %c2 : tensor<2x3x4xf32>\n",
      "  %3 = tensor.empty(%0, %1, %2) : tensor<?x?x?xf32>\n",
      "  %4 = tensor.cast %arg1 : tensor<?x?x?xf32> to tensor<2x?x?xf32>\n",
      "  %5 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0, %4 : tensor<2x3x4xf32>, tensor<2x?x?xf32>)\n",
      "    outs(%3 : tensor<?x?x?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32, %arg4 : f32):\n",
      "    %9 = arith.addf %arg2, %arg3 : f32\n",
      "    linalg.yield %9 : f32\n",
      "  } -> (tensor<?x?x?xf32>)\n",
      "  %6 = tensor.cast %5 : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "  return %6: tensor<2x3x4xf32>\n",
      "    //  CHECK:      %[[CAST_ARG1:.*]] = tensor.cast %[[ARG1]] : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "    //  CHECK-NEXT: %[[GENERIC_OP:.*]] = linalg.generic\n",
      "    //  CHECK-SAME: ins(%[[ARG0]], %[[CAST_ARG1]] : tensor<2x3x4xf32>, tensor<2x3x4xf32>)\n",
      "    //  CHECK-SAME: outs({{.*}} : tensor<2x3x4xf32>)\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "// CHECK-LABEL: func @static_output_with_cast\n",
      "// CHECK-SAME:  (%[[ARG0:.*]]: tensor<?x?x?xf32>, %[[ARG1:.*]]: tensor<?x?x?xf32>, %[[ARG2:.*]]: tensor<2x3x4xf32>) -> tensor<2x3x4xf32> {\n",
      "func.func @static_output_with_cast(%arg0 : tensor<?x?x?xf32>, %arg1: tensor<?x?x?xf32>, %arg2: tensor<2x3x4xf32>) -> tensor<2x3x4xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %0 = tensor.dim %arg2, %c0 : tensor<2x3x4xf32>\n",
      "  %1 = tensor.dim %arg2, %c1 : tensor<2x3x4xf32>\n",
      "  %2 = tensor.dim %arg2, %c2 : tensor<2x3x4xf32>\n",
      "  %3 = tensor.empty(%0, %1, %2) : tensor<?x?x?xf32>\n",
      "  %4 = tensor.cast %3 : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "  %5 = tensor.cast %arg1 : tensor<?x?x?xf32> to tensor<2x?x?xf32>\n",
      "  %6 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0, %5 : tensor<?x?x?xf32>, tensor<2x?x?xf32>)\n",
      "    outs(%4 : tensor<2x3x4xf32>) {\n",
      "  ^bb0(%arg3 : f32, %arg4 : f32, %arg5 : f32):\n",
      "    %9 = arith.addf %arg3, %arg4 : f32\n",
      "    linalg.yield %9 : f32\n",
      "  } -> (tensor<2x3x4xf32>)\n",
      "  return %6: tensor<2x3x4xf32>\n",
      "    //  CHECK:      %[[CAST_ARG0:.*]] = tensor.cast %[[ARG0]] : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "    //  CHECK-NEXT: %[[CAST_ARG1:.*]] = tensor.cast %[[ARG1]] : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "    //  CHECK-NEXT: %[[GENERIC_OP:.*]] = linalg.generic\n",
      "    //  CHECK-SAME: ins(%[[CAST_ARG0]], %[[CAST_ARG1]] : tensor<2x3x4xf32>, tensor<2x3x4xf32>)\n",
      "    //  CHECK-SAME: outs({{.*}} : tensor<2x3x4xf32>)\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// This test checks the folding of tensor.cast operation when the source value of cast\n",
      "// has more static information than the destination value.\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "// CHECK-LABEL: func @cast_source\n",
      "// CHECK-SAME:  (%[[ARG0:.*]]: tensor<2x3x4xf32>, %[[ARG1:.*]]: tensor<2x3x4xf32>) -> tensor<2x3x4xf32> {\n",
      "func.func @cast_source(%arg0 : tensor<2x3x4xf32>, %arg1: tensor<2x3x4xf32>) -> tensor<2x3x4xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %0 = tensor.dim %arg0, %c0 : tensor<2x3x4xf32>\n",
      "  %1 = tensor.dim %arg0, %c1 : tensor<2x3x4xf32>\n",
      "  %2 = tensor.dim %arg0, %c2 : tensor<2x3x4xf32>\n",
      "  %3 = tensor.empty(%0, %1, %2) : tensor<?x?x?xf32>\n",
      "  %4 = tensor.cast %arg0 : tensor<2x3x4xf32> to tensor<2x?x?xf32>\n",
      "  %5 = tensor.cast %arg1 : tensor<2x3x4xf32> to tensor<2x?x?xf32>\n",
      "  %6 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%4, %5 : tensor<2x?x?xf32>, tensor<2x?x?xf32>)\n",
      "    outs(%3 : tensor<?x?x?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32, %arg4 : f32):\n",
      "    %9 = arith.addf %arg2, %arg3 : f32\n",
      "    linalg.yield %9 : f32\n",
      "  } -> (tensor<?x?x?xf32>)\n",
      "  %7 = tensor.cast %6 : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "  return %7: tensor<2x3x4xf32>\n",
      "    //  CHECK:      %[[GENERIC_OP:.*]] = linalg.generic\n",
      "    //  CHECK-SAME: ins(%[[ARG0]], %[[ARG1]] : tensor<2x3x4xf32>, tensor<2x3x4xf32>)\n",
      "    //  CHECK-SAME: outs({{.*}} : tensor<2x3x4xf32>)\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>\n",
      "// CHECK-LABEL: func @cast_dest\n",
      "// CHECK-SAME:  (%[[ARG0:.*]]: tensor<?x?x?xf32>, %[[ARG1:.*]]: tensor<1x?x?xf32>,\n",
      "func.func @cast_dest(%arg0: tensor<?x?x?xf32>, %arg1: tensor<1x?x?xf32>, %arg2: index, %arg3: index, %arg4: index) -> tensor<?x?x?xf32> {\n",
      "  %0 = tensor.empty(%arg2, %arg3, %arg4) : tensor<?x?x?xf32>\n",
      "  %1 = tensor.cast %arg1 : tensor<1x?x?xf32> to tensor<?x?x?xf32>\n",
      "  %2 = linalg.generic {\n",
      "    indexing_maps = [#map, #map, #map],\n",
      "    iterator_types = [\"parallel\", \"parallel\", \"parallel\"]\n",
      "  } ins(%arg0, %arg1 : tensor<?x?x?xf32>, tensor<1x?x?xf32>)\n",
      "    outs(%0 : tensor<?x?x?xf32>) {\n",
      "  ^bb0(%arg5: f32, %arg6: f32, %arg7: f32):\n",
      "    %3 = arith.subf %arg5, %arg6 : f32\n",
      "    linalg.yield %3 : f32\n",
      "  } -> tensor<?x?x?xf32>\n",
      "  return %2 : tensor<?x?x?xf32>\n",
      "// CHECK:      %[[GENERIC_OP:.*]] = linalg.generic\n",
      "// CHECK-SAME: ins(%{{.*}}, %[[ARG1]] : tensor<1x?x?xf32>, tensor<1x?x?xf32>)\n",
      "// CHECK-SAME: outs(%{{.*}} : tensor<1x?x?xf32>)\n",
      "// CHECK: tensor.cast %[[GENERIC_OP]] : tensor<1x?x?xf32> to tensor<?x?x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "//       CHECK: #[[$MAP:.+]] = affine_map<()[s0] -> (s0 + 1)>\n",
      "// CHECK-LABEL: func @insert_pad_into_fill\n",
      "//  CHECK-SAME: (%[[INPUT:.+]]: tensor<?x?x?xf32>, %[[LOW0:.+]]: index, %[[LOW1:.+]]: index, %{{.+}}: index, %{{.+}}: index)\n",
      "//   CHECK-DAG: %[[C0:.+]] = arith.constant 0 : index\n",
      "//   CHECK-DAG: %[[C1:.+]] = arith.constant 1 : index\n",
      "//   CHECK-DAG: %[[C2:.+]] = arith.constant 2 : index\n",
      "//   CHECK-DAG: %[[F0:.+]] = arith.constant 0.000000e+00 : f32\n",
      "//       CHECK: %[[INIT:.+]] = tensor.empty()\n",
      "//       CHECK: %[[FILL:.+]] = linalg.fill ins(%[[F0]]{{.*}}outs(%[[INIT]]\n",
      "//       CHECK: %[[OFFSET1:.+]] = affine.apply #[[$MAP]]()[%[[LOW1]]]\n",
      "//       CHECK: %[[D0:.+]] = tensor.dim %[[INPUT]], %[[C0]] : tensor<?x?x?xf32>\n",
      "//       CHECK: %[[D1:.+]] = tensor.dim %[[INPUT]], %[[C1]] : tensor<?x?x?xf32>\n",
      "//       CHECK: %[[D2:.+]] = tensor.dim %[[INPUT]], %[[C2]] : tensor<?x?x?xf32>\n",
      "//       CHECK: tensor.insert_slice %[[INPUT]] into %[[FILL]][%[[LOW0]], %[[OFFSET1]], 2] [%[[D0]], %[[D1]], %[[D2]]] [1, 1, 1]\n",
      "func.func @insert_pad_into_fill(%input: tensor<?x?x?xf32>, %low0: index, %low1: index, %high1: index, %high2: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %pad = tensor.pad %input low[%low0, %low1, %c0] high[%c0, %high1, %high2] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<?x?x?xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  %0 = tensor.insert_slice %pad into %fill[0, 1, 2] [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %0: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @multi_insert_pad_into_fill\n",
      "//  CHECK-SAME: (%[[INPUT:.+]]: tensor<7x123x124xf32>, %[[A:.+]]: tensor<8x128x128xf32>, %[[OFFSET:.+]]: index)\n",
      "//       CHECK:   %[[FILL:.+]] = linalg.fill\n",
      "//       CHECK:   %[[INSERT0:.+]] = tensor.insert_slice %[[A]] into %[[FILL]][%[[OFFSET]], 0, 0] [8, 128, 128] [1, 1, 1]\n",
      "//       CHECK:   %[[INSERT1:.+]] = tensor.insert_slice %[[A]] into %[[INSERT0]][0, 128, %[[OFFSET]]] [8, 128, 128] [1, 1, 1]\n",
      "//       CHECK:                  tensor.insert_slice %[[INPUT]] into %[[INSERT1]][1, 2, 256] [7, 123, 124] [1, 1, 1]\n",
      "func.func @multi_insert_pad_into_fill(%input: tensor<7x123x124xf32>, %a: tensor<8x128x128xf32>, %offset: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %pad = tensor.pad %input low[1, 2, 0] high[0, 3, 4] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<7x123x124xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  %0 = tensor.insert_slice %a   into %fill[%offset, 0, 0]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %1 = tensor.insert_slice %a   into %0   [0, 128, %offset][8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %2 = tensor.insert_slice %pad into %1   [0, 0, 256]      [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %2: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @multi_insert_pad_into_fill_overlap\n",
      "func.func @multi_insert_pad_into_fill_overlap(%input: tensor<7x123x124xf32>, %a: tensor<8x128x128xf32>, %offset: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  // CHECK: tensor.pad\n",
      "  %pad = tensor.pad %input low[1, 2, 0] high[0, 3, 4] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<7x123x124xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  %0 = tensor.insert_slice %a   into %fill[%offset, 0, 0]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %1 = tensor.insert_slice %a   into %0   [0, 0, 129]      [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  // Range overlap with %1 at dim#3\n",
      "  %2 = tensor.insert_slice %pad into %1   [0, 0, 256]      [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %2: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @multi_insert_pad_into_fill_overlap\n",
      "func.func @multi_insert_pad_into_fill_overlap(%input: tensor<7x123x124xf32>, %a: tensor<8x128x128xf32>, %offset: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  // CHECK: tensor.pad\n",
      "  %pad = tensor.pad %input low[1, 2, 0] high[0, 3, 4] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<7x123x124xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  %0 = tensor.insert_slice %a   into %fill[0, 0, %offset]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %1 = tensor.insert_slice %a   into %0   [0, 128, 255]    [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  // Range overlap with %0 at dim#3\n",
      "  %2 = tensor.insert_slice %pad into %1   [0, 0, 256]      [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %2: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @multi_insert_pad_into_fill\n",
      "func.func @multi_insert_pad_into_fill(%input: tensor<7x123x124xf32>, %a: tensor<8x128x128xf32>, %offset: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  // CHECK-NOT: tensor.pad\n",
      "  %pad = tensor.pad %input low[1, 2, 0] high[0, 3, 4] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<7x123x124xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  %fill = linalg.fill ins(%f0 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  // Overlap btween %0 and %1 is fine but not with %2 is fine.\n",
      "  // CHECK-COUNT-3: tensor.insert_slice\n",
      "  %0 = tensor.insert_slice %a   into %fill[0, 0, %offset]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %1 = tensor.insert_slice %a   into %0   [0, 1, %offset]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %2 = tensor.insert_slice %pad into %1   [0, 256, 256]    [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %2: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @multi_insert_pad_into_fill_mismatch\n",
      "func.func @multi_insert_pad_into_fill_mismatch(%input: tensor<7x123x124xf32>, %a: tensor<8x128x128xf32>, %offset: index) -> tensor<8x384x384xf32> {\n",
      "  %f0 = arith.constant 0.0 : f32\n",
      "  %f1 = arith.constant 1.0 : f32\n",
      "  %c0 = arith.constant 0 : index\n",
      "  // CHECK: tensor.pad\n",
      "  %pad = tensor.pad %input low[1, 2, 0] high[0, 3, 4] {\n",
      "  ^bb0(%arg3: index, %arg4: index, %arg5: index):\n",
      "    tensor.yield %f0 : f32\n",
      "  } : tensor<7x123x124xf32> to tensor<8x128x128xf32>\n",
      "  %empty = tensor.empty() : tensor<8x384x384xf32>\n",
      "  // Different filling value than padding value.\n",
      "  %fill = linalg.fill ins(%f1 : f32) outs(%empty : tensor<8x384x384xf32>) -> tensor<8x384x384xf32>\n",
      "  %0 = tensor.insert_slice %a   into %fill[%offset, 0, 0]  [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %1 = tensor.insert_slice %a   into %0   [0, 128, %offset][8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  %2 = tensor.insert_slice %pad into %1   [0, 0, 256]      [8, 128, 128] [1, 1, 1] : tensor<8x128x128xf32> into tensor<8x384x384xf32>\n",
      "  return %2: tensor<8x384x384xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "func.func @fold_linalgop_with_cast_consumer(%arg0 : tensor<?x?xf32>, %arg1 : tensor<?x?xf32>,\n",
      "    %arg2 : tensor<?x?xf32>) -> (tensor<4x8xf32>, tensor<?x?xf32>) {\n",
      "  %0 = linalg.matmul ins(%arg0, %arg1 : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "      outs(%arg2 : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "  %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<4x8xf32>\n",
      "  return %1, %0 : tensor<4x8xf32>, tensor<?x?xf32>\n",
      "}\n",
      "//       CHECK: func @fold_linalgop_with_cast_consumer(\n",
      "//  CHECK-SAME:     %[[ARG0:[a-zA-Z0-9]+]]: tensor<?x?xf32>\n",
      "//  CHECK-SAME:     %[[ARG1:[a-zA-Z0-9]+]]: tensor<?x?xf32>\n",
      "//  CHECK-SAME:     %[[ARG2:[a-zA-Z0-9]+]]: tensor<?x?xf32>)\n",
      "//   CHECK-DAG:  %[[LHS_CAST:.+]] = tensor.cast %[[ARG0]] : tensor<?x?xf32> to tensor<4x?xf32>\n",
      "//   CHECK-DAG:  %[[RHS_CAST:.+]] = tensor.cast %[[ARG1]] : tensor<?x?xf32> to tensor<?x8xf32>\n",
      "//   CHECK-DAG:  %[[OUT_CAST:.+]] = tensor.cast %[[ARG2]] : tensor<?x?xf32> to tensor<4x8xf32>\n",
      "//       CHECK:  %[[MATMUL:.+]] = linalg.matmul\n",
      "//  CHECK-SAME:      ins(%[[LHS_CAST]], %[[RHS_CAST]] :\n",
      "//  CHECK-SAME:      outs(%[[OUT_CAST]] :\n",
      "//       CHECK:  %[[RESULT_CAST:.+]] = tensor.cast %[[MATMUL]]\n",
      "//       CHECK:  return %[[MATMUL]], %[[RESULT_CAST]]\n",
      "\n",
      "// -----\n",
      "\n",
      "func.func private @some_use(%0 : tensor<4x8xf32>)\n",
      "\n",
      "func.func @linalgop_with_cond_cast_consumer(%arg0 : tensor<?x?xf32>, %arg1 : tensor<?x?xf32>,\n",
      "    %arg2 : tensor<?x?xf32>, %arg3 : i1) -> tensor<?x?xf32> {\n",
      "  %0 = linalg.matmul ins(%arg0, %arg1 : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "      outs(%arg2 : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "  scf.if %arg3 {\n",
      "    %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<4x8xf32>\n",
      "    func.call @some_use(%1) : (tensor<4x8xf32>) -> ()\n",
      "  }\n",
      "  return %0 : tensor<?x?xf32>\n",
      "}\n",
      "\n",
      "// Check conditionally reachable cast is not folded into producer.\n",
      "// CHECK-LABEL: func @linalgop_with_cond_cast_consumer\n",
      "//  CHECK-SAME:     (%[[ARG0:.*]]: tensor<?x?xf32>, %[[ARG1:.*]]: tensor<?x?xf32>, %[[ARG2:.*]]: tensor<?x?xf32>, %[[ARG3:.*]]: i1)\n",
      "//       CHECK: %[[RES:.*]] = linalg.matmul ins(%[[ARG0]], %[[ARG1]] : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "//  CHECK-SAME:      outs(%[[ARG2]] : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "//       CHECK: scf.if %[[ARG3]] {\n",
      "//       CHECK:   %[[CAST:.*]] = tensor.cast %[[RES]] : tensor<?x?xf32> to tensor<4x8xf32>\n",
      "//       CHECK:   func.call @some_use(%[[CAST]]) : (tensor<4x8xf32>) -> ()\n",
      "//       CHECK: }\n",
      "//       CHECK: return %[[RES]] : tensor<?x?xf32>\n",
      "\n",
      "\n",
      "// -----\n",
      "\n",
      "func.func @fold_conv_op_with_cast_consumer(%arg0 : tensor<?x?x?x?xf32>,\n",
      "    %arg1 : tensor<?x?x?x?xf32>,  %arg2 : tensor<?x?x?x?xf32>) ->\n",
      "    (tensor<4x8x12x16xf32>, tensor<?x?x?x?xf32>) {\n",
      "  %0 = linalg.conv_2d_nchw_fchw ins(%arg0, %arg1 : tensor<?x?x?x?xf32>, tensor<?x?x?x?xf32>)\n",
      "      outs(%arg2 : tensor<?x?x?x?xf32>) -> tensor<?x?x?x?xf32>\n",
      "  %1 = tensor.cast %0 : tensor<?x?x?x?xf32> to tensor<4x8x12x16xf32>\n",
      "  return %1, %0 : tensor<4x8x12x16xf32>, tensor<?x?x?x?xf32>\n",
      "}\n",
      "//       CHECK: func @fold_conv_op_with_cast_consumer(\n",
      "//  CHECK-SAME:     %[[ARG0:[a-zA-Z0-9]+]]: tensor<?x?x?x?xf32>\n",
      "//  CHECK-SAME:     %[[ARG1:[a-zA-Z0-9]+]]: tensor<?x?x?x?xf32>\n",
      "//  CHECK-SAME:     %[[ARG2:[a-zA-Z0-9]+]]: tensor<?x?x?x?xf32>)\n",
      "//       CHECK:  %[[OUT_CAST:.+]] = tensor.cast %[[ARG2]] : tensor<?x?x?x?xf32> to tensor<4x8x12x16xf32>\n",
      "//       CHECK:  %[[CONV:.+]] = linalg.conv_2d_nchw_fchw\n",
      "//  CHECK-SAME:      ins(%[[ARG0]], %[[ARG1]] :\n",
      "//  CHECK-SAME:      outs(%[[OUT_CAST]] :\n",
      "//       CHECK:  %[[RESULT_CAST:.+]] = tensor.cast %[[CONV]]\n",
      "//       CHECK:  return %[[CONV]], %[[RESULT_CAST]]\n",
      "\n",
      "// -----\n",
      "\n",
      "func.func @fold_multi_use_generic_op_with_consumer(%arg0 : tensor<?x?x?xf32>) -> (tensor<?x?x?xf32>, tensor<2x3x4xf32>) {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c2 = arith.constant 2 : index\n",
      "  %d0 = tensor.dim %arg0, %c0 : tensor<?x?x?xf32>\n",
      "  %d1 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32>\n",
      "  %d2 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32>\n",
      "  %empty1 = tensor.empty(%d1, %d2, %d0) : tensor<?x?x?xf32>\n",
      "  %empty2 = tensor.empty(%d2, %d1, %d0) : tensor<?x?x?xf32>\n",
      "  %0:2 = linalg.generic {\n",
      "      iterator_types = [\"parallel\", \"parallel\", \"parallel\"],\n",
      "      indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d1, d2)>,\n",
      "                       affine_map<(d0, d1, d2) -> (d1, d2, d0)>,\n",
      "                       affine_map<(d0, d1, d2) -> (d2, d1, d0)>]}\n",
      "      ins(%arg0 : tensor<?x?x?xf32>) outs(%empty1, %empty2 : tensor<?x?x?xf32>, tensor<?x?x?xf32>) {\n",
      "    ^bb0(%b0 : f32, %b1 : f32, %b2 : f32) :\n",
      "      linalg.yield %b0, %b0 : f32, f32\n",
      "    } -> (tensor<?x?x?xf32>, tensor<?x?x?xf32>)\n",
      "  %1 = tensor.cast %0#1 : tensor<?x?x?xf32> to tensor<2x3x4xf32>\n",
      "  return %0#0, %1 : tensor<?x?x?xf32>, tensor<2x3x4xf32>\n",
      "}\n",
      "//       CHECK: func @fold_multi_use_generic_op_with_consumer\n",
      "//  CHECK-SAME:     %[[ARG0:.+]]: tensor<?x?x?xf32>\n",
      "//   CHECK-DAG:   %[[INIT1:.+]] = tensor.empty() : tensor<2x3x4xf32>\n",
      "//   CHECK-DAG:   %[[CAST:.+]] = tensor.cast %[[ARG0]] : tensor<?x?x?xf32> to tensor<4x3x2xf32>\n",
      "//   CHECK-DAG:   %[[INIT2:.+]] = tensor.empty() : tensor<3x2x4xf32>\n",
      "//       CHECK:   %[[GENERIC:.+]]:2 = linalg.generic\n",
      "//  CHECK-SAME:       ins(%[[CAST]] :\n",
      "//  CHECK-SAME:       outs(%[[INIT2]], %[[INIT1]] :\n",
      "//       CHECK:   %[[RETURN_CAST:.+]] = tensor.cast %[[GENERIC]]#0 : tensor<3x2x4xf32> to tensor<?x?x?xf32>\n",
      "//       CHECK:   return %[[RETURN_CAST]], %[[GENERIC]]#1\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0) -> (d0)>\n",
      "func.func @identity_mixed(%arg0 : tensor<?xf32>, %arg1: memref<?xf32>) {\n",
      "  linalg.generic {\n",
      "    indexing_maps = [#map, #map],\n",
      "    iterator_types = [\"parallel\"]\n",
      "  } ins(%arg0 : tensor<?xf32>)\n",
      "    outs(%arg1 : memref<?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32):\n",
      "    linalg.yield %arg2 : f32\n",
      "  }\n",
      "  return\n",
      "}\n",
      "\n",
      "// There was a crash in EraseIdentityGenericOp for generic with mixed semantics.\n",
      "// For now, check generic remained unchanged.\n",
      "// CHECK-LABEL: func @identity_mixed\n",
      "//  CHECK-SAME:     (%[[ARG1:.*]]: tensor<?xf32>, %[[ARG2:.*]]: memref<?xf32>)\n",
      "//       CHECK:     linalg.generic {\n",
      "//  CHECK-SAME:    indexing_maps = [#map, #map],\n",
      "//  CHECK-SAME:    iterator_types = [\"parallel\"]\n",
      "//  CHECK-SAME:  } ins(%[[ARG1]] : tensor<?xf32>)\n",
      "//  CHECK-SAME:    outs(%[[ARG2]] : memref<?xf32>) {\n",
      "\n",
      "// -----\n",
      "\n",
      "// Just make sure that we don't crash.\n",
      "\n",
      "// CHECK-LABEL: func @dedeplicate_regression_test\n",
      "func.func @dedeplicate_regression_test(%0: tensor<4xf32>, %1: memref<4xf32>) {\n",
      "  %36 = linalg.generic\n",
      "    {indexing_maps = [affine_map<(d0) -> (d0)>,\n",
      "                      affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>],\n",
      "     iterator_types = [\"parallel\"]}\n",
      "    ins(%1, %1 : memref<4xf32>, memref<4xf32>)\n",
      "    outs(%0 : tensor<4xf32>) {\n",
      "  ^bb0(%in: f32, %in_24: f32, %out: f32):\n",
      "    linalg.yield %in : f32\n",
      "  } -> tensor<4xf32>\n",
      "  %53 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>],\n",
      "                        iterator_types = [\"parallel\"]}\n",
      "                        outs(%36 : tensor<4xf32>) {\n",
      "  ^bb0(%out: f32):\n",
      "    linalg.yield %out : f32\n",
      "  } -> tensor<4xf32>\n",
      "  return\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#map = affine_map<(d0) -> (d0)>\n",
      "func.func @cast_producer_mixed(%arg0 : tensor<5xf32>, %arg1: memref<?xf32>) {\n",
      "  %0 = tensor.cast %arg0 : tensor<5xf32> to tensor<?xf32>\n",
      "  linalg.generic {\n",
      "    indexing_maps = [#map, #map],\n",
      "    iterator_types = [\"parallel\"]\n",
      "  } ins(%0 : tensor<?xf32>)\n",
      "    outs(%arg1 : memref<?xf32>) {\n",
      "  ^bb0(%arg2 : f32, %arg3 : f32):\n",
      "    linalg.yield %arg2 : f32\n",
      "  }\n",
      "  return\n",
      "}\n",
      "\n",
      "// We need a mixed linalg as a bridge between tensor and memref worlds.\n",
      "// CHECK-LABEL: func @cast_producer_mixed\n",
      "//  CHECK-SAME:     (%[[ARG1:.*]]: tensor<5xf32>, %[[ARG2:.*]]: memref<?xf32>)\n",
      "//       CHECK:     linalg.generic {\n",
      "//  CHECK-SAME:    indexing_maps = [#map, #map],\n",
      "//  CHECK-SAME:    iterator_types = [\"parallel\"]\n",
      "//  CHECK-SAME:  } ins(%[[ARG1]] : tensor<5xf32>)\n",
      "//  CHECK-SAME:    outs(%[[ARG2]] : memref<?xf32>) {\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_body(code, start_marker, end_marker):\n",
    "    start_idx = code.index(start_marker)\n",
    "    end_idx = code.index(end_marker) + len(end_marker) \n",
    "    # print(start_idx, \" \", end_idx)\n",
    "    return code[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 提取正文内容\n",
    "start_marker = \"func.func @\"\n",
    "end_marker = \"return\\n}\"\n",
    "\n",
    "code_body = extract_code_body(code_content,start_marker,end_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func.func @memref_cast(%a: index, %b: index) -> memref<?x?xf32> {\n",
      "  %c0 = arith.constant 0 : index\n",
      "  %c1 = arith.constant 1 : index\n",
      "  %c8 = arith.constant 8 : index\n",
      "  %c16 = arith.constant 16 : index\n",
      "  %1 = memref.alloc (%b) : memref<?xi8>\n",
      "  %2 = memref.view %1[%c0][] : memref<?xi8> to memref<16x16xf32>\n",
      "  %3 = memref.cast %2 : memref<16x16xf32> to memref<?x?xf32>\n",
      "\n",
      "  // CHECK:  linalg.matmul ins({{.*}}memref<16x16xf32>, memref<16x16xf32>) outs({{.*}}memref<16x16xf32>)\n",
      "  linalg.matmul ins(%3, %3: memref<?x?xf32>, memref<?x?xf32>)\n",
      "               outs(%3: memref<?x?xf32>)\n",
      "  return %3: memref<?x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "#accesses = [\n",
      "  affine_map<(i) -> (i)>\n",
      "]\n",
      "\n",
      "#trait = {\n",
      "  indexing_maps = #accesses,\n",
      "  iterator_types = [\"parallel\"]\n",
      "}\n",
      "\n",
      "func.func @dce_zero_memref(%arg0 : memref<0xf32>, %arg1: tensor<0xf32>) -> tensor<0xf32> {\n",
      "  // memref<0x32> is expected to be dce'ed\n",
      "  memref.copy %arg0, %arg0 : memref<0xf32> to memref<0xf32>\n",
      "\n",
      "  // tensor<0xf32> cannot be dce'ed\n",
      "  %1 = linalg.generic #trait outs(%arg1 : tensor<0xf32>) {\n",
      "  ^bb(%0: f32) :\n",
      "    linalg.yield %0 : f32\n",
      "  } -> tensor<0xf32>\n",
      "\n",
      "  return %1: tensor<0xf32>\n",
      "}\n",
      "// CHECK-LABEL: @dce_zero_memref\n",
      "//  CHECK-SAME:   %[[ARG0:[a-zA-Z0-9_]+]]: memref<0xf32>\n",
      "//  CHECK-SAME:   %[[ARG1:[a-zA-Z0-9_]+]]: tensor<0xf32>\n",
      "//   CHECK-NOT:   memref.copy\n",
      "//  CHECK-NEXT:   return %[[ARG1]]\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @tensor.cast(\n",
      "func.func @tensor.cast(%a : tensor<3x4xf32>, %b : tensor<4x?xf32>, %c : tensor<3x?xf32>)\n",
      "  -> tensor<3x?xf32>\n",
      "{\n",
      "  %ta = tensor.cast %a : tensor<3x4xf32> to tensor<?x?xf32>\n",
      "  %tb = tensor.cast %b : tensor<4x?xf32> to tensor<?x?xf32>\n",
      "  %tc = tensor.cast %c : tensor<3x?xf32> to tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  linalg.matmul ins({{.*}}tensor<3x4xf32>, tensor<4x?xf32>)\n",
      "  // CHECK-SAME:    outs({{.*}}tensor<3x?xf32>) -> tensor<3x?xf32>\n",
      "  %0 = linalg.matmul ins(%ta, %tb: tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "                    outs(%tc: tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<3x?xf32>\n",
      "\n",
      "  return %1: tensor<3x?xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @tensor.cast.unranked(\n",
      "func.func @tensor.cast.unranked(%a : tensor<*xf32>, %b : tensor<*xf32>, %c : tensor<*xf32>)\n",
      "  -> tensor<*xf32>\n",
      "{\n",
      "  //      CHECK:  tensor.cast\n",
      "  //      CHECK:  tensor.cast\n",
      "  //      CHECK:  tensor.cast\n",
      "  %ta = tensor.cast %a : tensor<*xf32> to tensor<?x?xf32>\n",
      "  %tb = tensor.cast %b : tensor<*xf32> to tensor<?x?xf32>\n",
      "  %tc = tensor.cast %c : tensor<*xf32> to tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  linalg.matmul ins({{.*}}tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "  // CHECK-SAME:    outs({{.*}}tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "  %0 = linalg.matmul ins(%ta, %tb: tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "                    outs(%tc: tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  //      CHECK:  tensor.cast\n",
      "  %1 = tensor.cast %0 : tensor<?x?xf32> to tensor<*xf32>\n",
      "\n",
      "  return %1: tensor<*xf32>\n",
      "}\n",
      "\n",
      "// -----\n",
      "\n",
      "// CHECK-LABEL: func @linalg_effects(\n",
      "//  CHECK-SAME:     %[[A:[a-z0-9]*]]: tensor<?x?xf32>\n",
      "//  CHECK-SAME:     %[[B:[a-z0-9]*]]: memref<?x?xf32>\n",
      "//  CHECK-SAME:     %[[C:[a-z0-9]*]]: tensor<?x?xf32>\n",
      "func.func @linalg_effects(%a : tensor<?x?xf32>, %b : memref<?x?xf32>, %c : tensor<?x?xf32>) {\n",
      "  // CHECK-NOT:   %{{.*}} = linalg.matmul\n",
      "  %t = linalg.matmul ins(%a, %b : tensor<?x?xf32>, memref<?x?xf32>)\n",
      "                    outs(%c : tensor<?x?xf32>) -> tensor<?x?xf32>\n",
      "\n",
      "  // CHECK:   linalg.matmul\n",
      "  linalg.matmul ins(%a, %c : tensor<?x?xf32>, tensor<?x?xf32>)\n",
      "               outs(%b : memref<?x?xf32>)\n",
      "  return\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(code_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(.*?)(?=// -----$|$)\" \n",
    "statements = re.findall(pattern, code_content, re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1:\n",
      "Section 2:\n",
      "Section 3:\n",
      "Section 4:\n",
      "Section 5:\n",
      "Section 6:\n",
      "Section 7:\n",
      "Section 8:\n",
      "Section 9:\n",
      "Section 10:\n",
      "Section 11:\n",
      "Section 12:\n",
      "Section 13:\n",
      "Section 14:\n",
      "Section 15:\n",
      "Section 16:\n",
      "Section 17:\n",
      "Section 18:\n",
      "Section 19:\n",
      "Section 20:\n",
      "Section 21:\n",
      "Section 22:\n",
      "Section 23:\n",
      "Section 24:\n",
      "Section 25:\n",
      "Section 26:\n",
      "Section 27:\n",
      "Section 28:\n",
      "Section 29:\n",
      "Section 30:\n",
      "Section 31:\n",
      "Section 32:\n",
      "Section 33:\n",
      "Section 34:\n",
      "Section 35:\n",
      "Section 36:\n",
      "Section 37:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sections = re.split(r'\\s*// -----\\s*', code_content)\n",
    "sections = [section.strip() for section in sections if section.strip() != \"\"]\n",
    "\n",
    "for i, section in enumerate(sections, start=1):\n",
    "    print(f\"Section {i}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_content.index(\"// -----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(statements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = re.findall(r\"// RUN:(.+?)\\| FileCheck\", code_content, re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(statements)):\n",
    "    statements[i] = statements[i].replace('\\\\\\n// RUN:', '').replace('%s', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' mlir-opt  --sparse-tensor-conversion --canonicalize --cse ', ' mlir-opt  --post-sparsification-rewrite=\"enable-runtime-library=false enable-foreach=false\"  --canonicalize --cse ']\n"
     ]
    }
   ],
   "source": [
    "print(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 查找pass\n",
    "pass_command = extract_code_body(code_content,\"mlir-opt\",\"FileCheck\")\n",
    "pass_command = pass_command.replace('%s', '')\n",
    "cleaned_pass = pass_command.rsplit(' | FileCheck', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlir-opt  --sparse-tensor-conversion --canonicalize --cse\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "3 4\n",
      "3 5\n",
      "3 6\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    for j in [4, 5, 6]:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func.func @foo() {\n",
      "  %0 = arith.constant 0 : i32\n",
      "  return\n",
      "}\n",
      "func.func @bar() {\n",
      "  return\n",
      "}\n",
      "{-#\n",
      "  external_resources: {\n",
      "    mlir_reproducer: {\n",
      "      verify_each: true,\n",
      "      pipeline: \"builtin.module(func.func(cse,canonicalize{max-iterations=1 max-num-rewrites=-1 region-simplify=false top-down=false}))\",\n",
      "      disable_threading: true\n",
      "    }\n",
      "  }\n",
      "#-}  mlir-opt  --run-reproducer -dump-pass-pipeline 2>&1 \n",
      "func.func @foo() {\n",
      "  %0 = arith.constant 0 : i32\n",
      "  return\n",
      "}\n",
      "func.func @bar() {\n",
      "  return\n",
      "}\n",
      "{-#\n",
      "  external_resources: {\n",
      "    mlir_reproducer: {\n",
      "      verify_each: true,\n",
      "      pipeline: \"builtin.module(func.func(cse,canonicalize{max-iterations=1 max-num-rewrites=-1 region-simplify=false top-down=false}))\",\n",
      "      disable_threading: true\n",
      "    }\n",
      "  }\n",
      "#-}  mlir-opt  --run-reproducer -mlir-print-ir-before=cse 2>&1 \n"
     ]
    }
   ],
   "source": [
    "from extract import *\n",
    "text = '''\n",
    "// RUN: mlir-opt %s --run-reproducer -dump-pass-pipeline 2>&1 | FileCheck %s\n",
    "// RUN: mlir-opt %s --run-reproducer -mlir-print-ir-before=cse 2>&1 | FileCheck -check-prefix=BEFORE %s\n",
    "func.func @foo() {\n",
    "  %0 = arith.constant 0 : i32\n",
    "  return\n",
    "}\n",
    "\n",
    "func.func @bar() {\n",
    "  return\n",
    "}\n",
    "'''\n",
    "text = \"\"\"\n",
    "// RUN: mlir-opt %s --run-reproducer -dump-pass-pipeline 2>&1 | FileCheck %s\n",
    "// RUN: mlir-opt %s --run-reproducer -mlir-print-ir-before=cse 2>&1 | FileCheck -check-prefix=BEFORE %s\n",
    "\n",
    "func.func @foo() {\n",
    "  %0 = arith.constant 0 : i32\n",
    "  return\n",
    "}\n",
    "\n",
    "func.func @bar() {\n",
    "  return\n",
    "}\n",
    "\n",
    "{-#\n",
    "  external_resources: {\n",
    "    mlir_reproducer: {\n",
    "      verify_each: true,\n",
    "      // CHECK:  builtin.module(func.func(cse,canonicalize{ max-iterations=1 max-num-rewrites=-1 region-simplify=false test-convergence=false top-down=false}))\n",
    "      pipeline: \"builtin.module(func.func(cse,canonicalize{max-iterations=1 max-num-rewrites=-1 region-simplify=false top-down=false}))\",\n",
    "      disable_threading: true\n",
    "    }\n",
    "  }\n",
    "#-}\n",
    "\n",
    "// BEFORE: // -----// IR Dump Before{{.*}}CSE (cse) //----- //\n",
    "// BEFORE-NEXT: func @foo()\n",
    "// BEFORE: // -----// IR Dump Before{{.*}}CSE (cse) //----- //\n",
    "// BEFORE-NEXT: func @bar()\n",
    "// BEFORE-NOT: // -----// IR Dump Before{{.*}}Canonicalizer (canonicalize) //----- //\n",
    "// BEFORE-NOT: // -----// IR Dump After\n",
    "\"\"\"\n",
    "blocks = extract_block(text)\n",
    "passes = extract_pass(text)\n",
    "# 将新数据追加到 CSV 文件\n",
    "with open(csv_filename, \"a\", newline=\"\") as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  for b in blocks:\n",
    "      for p in passes:\n",
    "        csv_writer.writerow([b, p, default_cost])\n",
    "        print(b, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
